#! /usr/bin/python

# GPL licensed


import sys
import locale
import argparse
import json
import numpy as np
from core.coreTypes import *
from core.parser import Parser 
from misc.bw_aware import bw_aware_replacement

locale.setlocale( locale.LC_ALL, 'en_US.UTF-8' )

def parseAllocInfoFile(fname):
    col_parsers = {
        'app': int,
        'proc': int,
        'func': int,
        'alloc_time': int,
        'free_time': int,
        'bytes': int,
        'obj_id': int,
    }

    with open(fname) as infile:
        data = json.load(infile)

    assert 'version' in data and data['version'] == 1

    colnames = data['fields']
    dict_allocs = []
    for a in data['allocs']:
        assert len(a) == len(colnames)
        d = {col: col_parsers.get(col, lambda x: x)(v) for col,v in zip(colnames, a)}
        dict_allocs.append(d)

    data['allocs'] = dict_allocs

    # add a reverse mapping from callstacks to numeric object IDs
    data['callstacks'] = {cs[1+cs.find("["):cs.find("]")]: int(oid) for oid,cs in data['objects'].items()}
    return data


def parseTimeslotsInfoFile(fname):
    with open(fname) as infile:
        data = json.load(infile)

    assert 'version' in data and data['version'] == 1

    field_idx = {}
    assert 'field_idx' not in data
    data['field_idx'] = field_idx
    for i,f in enumerate(data['fields']):
        field_idx[f] = i

    return data

def pack_precise(items, mems, i):
    def itemSize(item): return item.size
    def itemRealSize(item): return item.realsize

    sizeLimit = mems[i].size
    getSize = itemSize
    P = {}
    for nItems in range(len(items)+1):
        for lim in range(sizeLimit+1):
            if nItems == 0:
                P[nItems,lim] = 0
            elif getSize(items[nItems-1]) > lim:
                P[nItems,lim] = P[nItems-1,lim]
            else:
                P[nItems,lim] = max(P[nItems-1,lim],
                                    P[nItems-1,lim-getSize(items[nItems-1])] +
                                    items[nItems-1].value[i])

    L = []
    nItems = len(items)
    lim = sizeLimit
    while nItems > 0:
        nItems -= 1
        if P[nItems+1,lim] != P[nItems,lim]:
            L.append(items[nItems])
            lim -= getSize(items[nItems])

    return L


def pack_greedy(items, mems, i):
    sizeLimit = mems[i].size
    items.sort(key=lambda x: x.value[i], reverse = True)
    L = []
    for item in items:
        if item.size <= sizeLimit:
            L.append(item)
            sizeLimit -= item.size
            if sizeLimit == 0: break
    return L


def pack_number(items, mems, i, lim):
    sizeLimit = mems[i].size
    L = []

    for item in items:
        if item.size <= sizeLimit and item.value[i] >= lim:
            print(item.value, lim)
            L.append(item)
            sizeLimit -= item.size
            if sizeLimit == 0: break
    return L


def print_distribution(distribution, systems, bytes):
    for j in range(len(systems)):
        print("System: ",j, " Objects: ",len(distribution[j]))
        for item in distribution[j]:
            print("Id: ",item.id, " Loads: ",item.loads, " Stores: ",item.stores, " Cost:", item.value)
        print("Occupancy: ", bytes[j] * 100 / systems[j].realsize)


def weight_objects(objects, systems, algorithm, metric, worst):
    if metric == "misses":
        for item in objects:
            item.value = [(item.loads + item.stores) / float(item.size)] * (len(systems)-1)
    elif metric == "latencies":
        for item in objects:
            item.value = [0] * (len(systems)-1)
            for i in range(len(systems)-1):
                item.value[i] = (item.loads * systems[i+1].load_latency + item.stores * systems[i+1].store_latency) / float(item.size)

    if algorithm.isdigit():
        tot = 0
        for item in objects:
            tot += item.value[0]
        for item in objects:
            item.value[0] = item.value[0] * 100 / tot

    # Be bad?
    if worst:
        max_value = 0
        for i in range(len(systems)-1):
            for item in objects:
                if item.value[i] > max_value: max_value = item.value[i]
            max_value += 1
            for item in objects:
                item.value[i] = max_value - item.value[i]


def get_distribution(objects, systems, algorithm, metric):
    distribution = [None] * len(systems)

    new_objects = [obj for obj in objects]

    for i in range(len(systems)-1):
        if algorithm == "precise":
            distribution[i] = pack_precise(new_objects, systems, i)
        elif algorithm == "greedy":
            distribution[i] = pack_greedy(new_objects, systems, i)
        elif algorithm.isdigit():
            distribution[i] = pack_number(new_objects, systems, i, float(algorithm))
        new_objects[:] = [item for item in new_objects if item not in distribution[i]]
    size = 0
    for o in new_objects: size += o.size
    if size > systems[-1].size:
        print("Error, doesn't fit")
        sys.exit(1)
    distribution[-1] = new_objects

    for placement in distribution:
        placement.sort(key=lambda x: x.callstack)

    return distribution


def fit_extra_objects(distribution, systems, allocs_info, app, proc, conc_activity_objs):
    def get_obj_id(memobj):
        if memobj.id != -1:
            return memobj.id
        return allocs_info['callstacks'].get(memobj.callstack, -1)

    dram_idx = [i for i,s in enumerate(systems) if s.name == 'DRAM'][0]
    selected_oids = [get_obj_id(o) for o in distribution[dram_idx]]

    num_procs = len(set(a['proc'] for a in allocs_info['allocs']))
    limit = systems[dram_idx].realsize / float(num_procs)

    assert len(selected_oids) == len(set(selected_oids)), "dups in selected_oids"

    # Group allocs (of selected app,proc) by object ID, as (timestamp, bytes delta) pairs
    objs = {}
    for alloc in allocs_info['allocs']:
        if alloc['app'] != app or alloc['proc'] != proc:
            continue
        # discard allocs with invalid free time
        if alloc['free_time'] <= alloc['alloc_time']:
            continue

        obj_deltas = objs.setdefault(alloc['obj_id'], [])

        obj_deltas.append((alloc['alloc_time'], alloc['bytes']))
        obj_deltas.append((alloc['free_time'], -1 * alloc['bytes']))

    # Convert lists of (time, bytes delta) to two numpy arrays, sorted by time
    np_objs = {}
    for obj_id in sorted(objs):
        if obj_id < 0:
            continue

        # merge deltas that have the same timestamp (realloc frees prev and allocates next in the same timestamp)
        deltas = {}
        for time,delta in objs[obj_id]:
            if time not in deltas:
                deltas[time] = 0
            deltas[time] += delta

        sorted_times = list(sorted(deltas.keys()))

        assert obj_id not in np_objs
        np_objs[obj_id] = {}
        np_objs[obj_id]['time'] = np.asarray(sorted_times)
        np_objs[obj_id]['bytes_delta'] = np.asarray([deltas[t] for t in sorted_times])

        # check that byte deltas are balanced
        assert np_objs[obj_id]['bytes_delta'].sum() == 0

    # merge
    merged_time = np.asarray([])
    for o in np_objs.values():
        merged_time = np.union1d(merged_time, o['time'])

    merged_values = np.zeros((len(np_objs), len(merged_time)))

    for i,oid in enumerate(sorted(np_objs.keys())):
        o = np_objs[oid]
        idxs = np.isin(merged_time, o['time']).nonzero()
        merged_values[i][idxs] = o['bytes_delta']

    #

    obj_ids = list(sorted(np_objs.keys()))


    sel_oids_in_objs = [x for x in selected_oids if x in obj_ids]

    idxs_sel_objs = list(sorted(obj_ids.index(x) for x in sel_oids_in_objs))

    stacked_values = np.cumsum(merged_values, axis=1) # turn byte-deltas to actual count, per object

    sel_values = stacked_values[idxs_sel_objs][:]
    total = np.sum(sel_values, axis=0)

    obj_values = {get_obj_id(o): o.value[0] for objs in distribution for o in objs}

    fits = []
    dont_fit = []

    # iterate over remaining objects sorted by descending cost
    sorted_np_objs = list(sorted(np_objs.keys(), key=lambda x: obj_values.get(x, 0.), reverse=True))
    # if we have high concurrent activity objects information, put them first
    if conc_activity_objs is not None:
        sorted_np_objs = [oid for oid in sorted_np_objs if oid in conc_activity_objs] + [oid for oid in sorted_np_objs if oid not in conc_activity_objs]
        assert len(sorted_np_objs) == len(np_objs)
        assert len(sorted_np_objs) == len(set(sorted_np_objs))

    for oid in sorted_np_objs:
        if oid in selected_oids:
            continue
        idx = obj_ids.index(oid)

        new_total = stacked_values[idx] + total
        if new_total.max() <= limit:
            fits.append(oid)
            total = new_total
        else:
            dont_fit.append(oid)

    objs_in_fits = [(memidx, o) for memidx,objs in enumerate(distribution) for o in objs if get_obj_id(o) in fits]
    for memidx,obj in objs_in_fits:
        assert memidx != dram_idx
        distribution[dram_idx].append(obj)
        distribution[memidx].remove(obj)



def main():
    parser = argparse.ArgumentParser(description='hmem_advisor, a memory object distribution tool for heterogeneous memory systems')
    #parser.add_argument('mem_config', type=str)
    #parser.add_argument('accesses_loads', type=argparse.FileType('rU'))
    #parser.add_argument('sizes', type=argparse.FileType('rU'))
    parser.add_argument('--mem-config', type=str, required=True)
    parser.add_argument('--loads', type=argparse.FileType('rU'), required=True)
    parser.add_argument('--sizes', type=argparse.FileType('rU'), required=True)
    parser.add_argument('--stores', type=argparse.FileType('rU'))
    parser.add_argument('--worst', action='store_true', default=False)
    parser.add_argument('--algo', type=str, default='greedy')
    parser.add_argument('--metric', type=str, default='latencies', choices=('latencies','misses'))
    parser.add_argument('--page', type=str, required=False, default="4096b")
    parser.add_argument('--verbose', action='store_true', default=False)
    parser.add_argument('--rank', type=int, default=0)
    parser.add_argument('--rank-statistics', type=str, default="Total")
    parser.add_argument('--visualizer', action='store_true', default=False)
    parser.add_argument('--allocs-info')
    parser.add_argument('--num-ranks', type=int)
    parser.add_argument('--disable-bw-aware', action='store_true', default=False)
    args = parser.parse_args()

    # Sanity checks
    if args.algo not in ("greedy", "precise") and not args.algo.isdigit():
        print("Algorithm", args.algo, "not supported")
        sys.exit(1)
    if args.algo.isdigit() and len(systems) > 2:
        print("Algorithm", args.algo, "only supported with 2 memory subsystems;", len(systems), "given")
        sys.exit(1)
    if not args.disable_bw_aware and not args.allocs_info:
        print('The bw-aware placement requires allocs-info data')
        sys.exit(1)
    if args.rank_statistics == 'Average' and not args.num_ranks:
        print('For --rank-statistics=Average you also have to specify --num-ranks')
        sys.exit(1)

    from misc.utils import text2bytes

    objects = []
    useless = []
    ignored = []
    pagesize = text2bytes(args.page)
    
    parser = Parser(args)
    parser.parse()

    items_loads, weights_loads = parser.loads_raw_obj.items, parser.loads_raw_obj.misses
    items_stores, weights_stores = parser.stores_raw_obj.items, parser.stores_raw_obj.misses
    items_sizes, weights_sizes = parser.sizes_raw_obj.items, parser.sizes_raw_obj.sizes
    systems = parser.mem_systems
 
    max_loads = 0
    max_stores = 0
    totv_loads = 0
    totv_stores = 0
    tot_size = 0

    # build object store, not assuming items are sorted across loads, stores, sizes
    # i.e. items_loads[i] doesn't necessarily correspond to items_sizes[i]
    # using items in loads data as key across sizes and stores
    for i in range(len(items_loads)):
        callstack = items_loads[i]
        loads = int(float(weights_loads[i]))
        stores = 0
        size = 0
        try:
            idx = items_sizes.index(items_loads[i])
            size = int(float(weights_sizes[idx]))
        except:
            size = 0
        if args.stores:
            try:
                idx = items_stores.index(items_loads[i])
                stores = int(float(weights_stores[idx]))
            except:
                stores = 0
        if not callstack == "Unresolved" and callstack.find("Memory object referenced by sampled address") == -1:
            if (loads > 0 or stores > 0) and size > 0:
                if loads > max_loads: max_loads = loads
                if stores > max_stores: max_stores = stores
                totv_loads += loads
                totv_stores += stores
                tot_size += size
                objects.append(MemoryObject(callstack, loads, stores, size, pagesize))
            else:
                useless.append(MemoryObject(callstack, loads, stores, size, pagesize))
        else:
            ignored.append(MemoryObject(callstack, loads, stores, size, pagesize))

    #raise Exception(objects)    

    # Run!
    weight_objects(objects, systems, args.algo, args.metric, args.worst)
    distribution = get_distribution(objects, systems, args.algo, args.metric)


    if args.allocs_info:
        process = 10
        allocs_info = parseAllocInfoFile(args.allocs_info)
        ca_objs = None

        fit_extra_objects(distribution, systems, allocs_info, 1, process, ca_objs)
        if not args.disable_bw_aware:
            bw_aware_replacement(distribution, systems, allocs_info)


    # print output
    for i in range(len(systems)):
        size = 0
        if args.verbose:
            print("--", systems[i].name, "-", systems[i].realsize, "bytes --")

        if not args.verbose and not args.visualizer:
            print("# Memory configuration for", systems[i].name, "with size", systems[i].realsize, "bytes")
            # print("# Memory configuration for", systems[i].name, "with size", systems[i].realsize, "bytes and latency", dram.load_latency/systems[i].load_latency, "times faster than DRAM")

        for mo in distribution[i]:
            if not args.verbose:
                if args.visualizer:
                    print(mo.callstack + ';' + str(mo.realsize) + ';' + str(mo.loads))
                else:
                    print(mo.comment() + mo.callstack + " @ " + systems[i].allocator)
            elif args.stores:
                print(mo.callstack, "-", mo.loads, "loads -", mo.stores, "stores -", mo.realsize, "bytes", " - cost ", str(mo.value))
            else:
                print(mo.callstack, "-", mo.loads, "loads -", mo.realsize, "bytes", " - cost ", str(mo.value))
            size += mo.realsize
        if args.verbose:
            print("--")
            if not args.stores:
                print(len(distribution[i]), "objects;", size, "bytes (" + str(size*100./systems[i].realsize) + "%);")
            else:
                print(len(distribution[i]), "objects;", size, "bytes (" + str(size*100./systems[i].realsize) + "%);")
            print


    if not args.verbose: sys.exit(0)

    print("-- WHEREVER --")
    size = 0
    for mo in useless:
        if args.stores:
            print(mo.callstack, "-", mo.loads, "loads -", mo.stores, "stores -", mo.realsize, "bytes")
        else:
            print(mo.callstack, "-", mo.loads, "loads -", mo.realsize, "bytes")
        size += mo.realsize
    print("--")
    print(len(useless), "objects;", size, "bytes")


if __name__ == '__main__':
    main()

